{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "616d65aa",
   "metadata": {},
   "source": [
    "# Sagemaker Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee7320a",
   "metadata": {},
   "source": [
    "This script predicts new data with the uploaded image in ECR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea32612e",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f188c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430e1eb4",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe50488",
   "metadata": {},
   "source": [
    "Modify according to your configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8893b148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucket name in S3\n",
    "bucket = \"hermione-sagemaker\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6ba2451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set session\n",
    "region_name=\"us-east-1\"\n",
    "boto3.setup_default_session(region_name=region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "797c5fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get user role\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8148140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get AWS Account ID\n",
    "account_number = boto3.client(\"sts\").get_caller_identity()[\"Account\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b1fba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image previous uploaded in ECR\n",
    "image_name = \"hermione-inference\"\n",
    "image_uri = f\"{account_number}.dkr.ecr.{region_name}.amazonaws.com/{image_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f907e610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and output paths to execute inference\n",
    "paths = {\n",
    "    'inference_processed': f\"s3://{bucket}/PREPROCESSING/INFERENCE_PROCESSED/inference.csv\",\n",
    "    'model': f\"s3://{bucket}/PREPROCESSING/MODEL/Hermione-train-2021-05-26-12-41-29-505/output/model.tar.gz\",\n",
    "    'output_path': f\"s3://{bucket}/PREPROCESSING/OUTPUT\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5fdfdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance to run the code\n",
    "instance_type=\"ml.m5.large\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fe64d7",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60b7dc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Receives the processed inference data in S3\n",
    "input_path = paths['inference_processed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3dc913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Receives the model created during the training in S3\n",
    "model_path = paths['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b69f31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the prediction in S3\n",
    "output_path = paths['output_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29f7ce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the model to access the ECR image\n",
    "model = sagemaker.model.Model(\n",
    "    image_uri= image_uri,\n",
    "    model_data=model_path,\n",
    "    role=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aacdf22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a transformer object from the trained model\n",
    "transformer = model.transformer(\n",
    "                          instance_count=1,\n",
    "                          instance_type=instance_type,   \n",
    "                          output_path=output_path,\n",
    "                          accept = 'text/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6452e276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................\u001b[34m2021-05-26 12:57:00,312 [INFO ] main com.amazonaws.ml.mms.ModelServer - \u001b[0m\n",
      "\u001b[34mMMS Home: /usr/local/lib/python3.8/dist-packages\u001b[0m\n",
      "\u001b[34mCurrent directory: /\u001b[0m\n",
      "\u001b[34mTemp directory: /tmp\u001b[0m\n",
      "\u001b[34mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[34mNumber of CPUs: 2\u001b[0m\n",
      "\u001b[34mMax heap size: 857 M\u001b[0m\n",
      "\u001b[34mPython executable: /usr/bin/python3\u001b[0m\n",
      "\u001b[34mConfig file: /etc/sagemaker-mms.properties\u001b[0m\n",
      "\u001b[34mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mModel Store: /.sagemaker/mms/models\u001b[0m\n",
      "\u001b[34mInitial Models: ALL\u001b[0m\n",
      "\u001b[34mLog dir: /logs\u001b[0m\n",
      "\u001b[34mMetrics dir: /logs\u001b[0m\n",
      "\u001b[34mNetty threads: 0\u001b[0m\n",
      "\u001b[34mNetty client threads: 0\u001b[0m\n",
      "\u001b[34mDefault workers per model: 2\u001b[0m\n",
      "\u001b[34mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[34mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[34mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[34mPreload model: false\u001b[0m\n",
      "\u001b[34mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:00,419 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-9000-model\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:00,506 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - model_service_worker started with args: --sock-type unix --sock-name /tmp/.mms.sock.9000 --handler serving.handler --model-path /.sagemaker/mms/models/model --model-name model --preload-model false --tmp-dir /tmp\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:00,508 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:00,509 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID] 23\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:00,509 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MMS worker started.\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:00,509 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.8.5\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:00,512 [INFO ] main com.amazonaws.ml.mms.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:00,517 [INFO ] main com.amazonaws.ml.mms.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:00,536 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:00,536 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:00,607 [INFO ] main com.amazonaws.ml.mms.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:00,613 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:00,614 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34mModel server started.\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:00,636 [WARN ] pool-2-thread-1 com.amazonaws.ml.mms.metrics.MetricCollector - worker pid is not available yet.\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:02,508 [WARN ] W-9000-model-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle - /usr/local/lib/python3.8/dist-packages/interpret_community/common/gpu_kmeans.py:30: UserWarning: cuML is required to use GPU explainers. Check https://rapids.ai/start.html         for more information on how to install it.\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:02,510 [WARN ] W-9000-model-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   warnings.warn(\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:02,510 [WARN ] W-9000-model-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle - /usr/local/lib/python3.8/dist-packages/interpret_community/common/gpu_kmeans.py:30: UserWarning: cuML is required to use GPU explainers. Check https://rapids.ai/start.html         for more information on how to install it.\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:02,510 [WARN ] W-9000-model-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle -   warnings.warn(\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:03,375 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - generated new fontManager\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:03,393 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - generated new fontManager\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:03,635 [WARN ] W-9000-model-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle - cuML is required to use GPU explainers. Check https://rapids.ai/start.html         for more information on how to install it.\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:03,658 [WARN ] W-9000-model-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle - cuML is required to use GPU explainers. Check https://rapids.ai/start.html         for more information on how to install it.\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:03,690 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Loading the model\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:03,715 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Loading the model\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:03,741 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000009-00000002-e6c9db643cbfeb7b-a47635f7\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:03,750 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3046\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:03,752 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-1\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:03,768 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000009-00000001-f549db643cbfeb7b-e2a66100\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:03,768 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3065\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:03,769 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-2\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:09,272 [INFO ] pool-1-thread-4 ACCESS_LOG - /169.254.255.130:59054 \"GET /ping HTTP/1.1\" 200 11\u001b[0m\n",
      "\u001b[35m2021-05-26 12:57:09,272 [INFO ] pool-1-thread-4 ACCESS_LOG - /169.254.255.130:59054 \"GET /ping HTTP/1.1\" 200 11\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:09,353 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:59058 \"GET /execution-parameters HTTP/1.1\" 404 2\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:09,462 [INFO ] W-model-1-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Predicting...\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:09,486 [INFO ] W-model-1-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Prediction Complete\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:09,491 [INFO ] W-model-1-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Saving\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:09,494 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 37\u001b[0m\n",
      "\u001b[34m2021-05-26 12:57:09,494 [INFO ] W-9000-model ACCESS_LOG - /169.254.255.130:59068 \"POST /invocations HTTP/1.1\" 200 42\u001b[0m\n",
      "\u001b[35m2021-05-26 12:57:09,353 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:59058 \"GET /execution-parameters HTTP/1.1\" 404 2\u001b[0m\n",
      "\u001b[35m2021-05-26 12:57:09,462 [INFO ] W-model-1-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Predicting...\u001b[0m\n",
      "\u001b[35m2021-05-26 12:57:09,486 [INFO ] W-model-1-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Prediction Complete\u001b[0m\n",
      "\u001b[35m2021-05-26 12:57:09,491 [INFO ] W-model-1-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Saving\u001b[0m\n",
      "\u001b[35m2021-05-26 12:57:09,494 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 37\u001b[0m\n",
      "\u001b[35m2021-05-26 12:57:09,494 [INFO ] W-9000-model ACCESS_LOG - /169.254.255.130:59068 \"POST /invocations HTTP/1.1\" 200 42\u001b[0m\n",
      "\u001b[32m2021-05-26T12:57:09.364:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n",
      "CPU times: user 547 ms, sys: 59 ms, total: 606 ms\n",
      "Wall time: 4min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Predicts the data\n",
    "transformer.transform(data=input_path, data_type='S3Prefix', content_type='text/csv', split_type='Line')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
