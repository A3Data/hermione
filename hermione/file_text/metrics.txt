from sklearn.metrics import *
import numpy as np
from sklearn.metrics import make_scorer

class Metrics:
    
    @classmethod
    def smape(cls, A, F):
        """
    	Calculates the smape value between the real and the predicted
    
    	Parameters
    	----------            
        A : array
            Target values
        F : array
            Predicted values
    
    	Returns
    	-------
    	float: smape value
    	"""
        return 100/len(A) * np.sum(np.abs(F - A) / (np.abs(A) + np.abs(F)))
    
    @classmethod
    def __custom_score(cls, y_true, y_pred):
        """
    	Creates a custom metric
    
    	Parameters
    	----------            
        y_true : array
                 Target values
        y_pred : array
                 Predicted values
    
    	Returns
    	-------
    	sklearn.metrics
    	"""
        #return sklearn.metrics.fbeta_score(y_true, y_pred, 2)
        pass
     
    @classmethod
    def cutomized(cls, y_true, y_pred):
        """
    	Creates a custom metric
    
    	Parameters
    	----------            
        y_true : array
                 Target values
        y_pred : array
                 Predicted values
    
    	Returns
    	-------
    	float
    	"""
        metrica_customizada = make_scorer(cls.__custom_score, greater_is_better=True)
        return metrica_customizada
        
    @classmethod
    def mape(cls, y_true, y_pred):
        """
    	Calculates the map value between the real and the predicted
    
    	Parameters
    	----------            
        y_true : array
                 Target values
        y_pred : array
                 Predicted values
    
    	Returns
    	-------
    	float : value of mape
    	"""
        y_true, y_pred = np.array(y_true), np.array(y_pred)
        return np.mean(np.abs(((y_true+1) - (y_pred+1)) / (y_true+1))) * 100

    
    @classmethod
    def regression(cls, y_true, y_pred):
        """
    	Calculates some metrics for regression problems
    
    	Parameters
    	----------            
        y_true : array
                 Target values
        y_pred : array
                 Predicted values
    
    	Returns
    	-------
    	dict : values for each metric
    	"""
        resultados = {'mean_absolute_error': round(mean_absolute_error(y_true, y_pred), 7),
                      'root_mean_squared_error': round(np.sqrt(mean_squared_error(y_true, y_pred)), 7),
                      'r2': round(r2_score(y_true, y_pred), 7),
                      'smape': round(cls.smape(y_true, y_pred), 7),
                      'mape': round(cls.mape(y_true, y_pred), 7)
                     }        
        return resultados
    
    @classmethod
    def __multiclass_classification(cls, y_true, y_pred, normalize=False, title="Matriz de confusão"):
        """
    	Calculates some metrics for multiclass classification problems
    
    	Parameters
    	----------            
        y_true    : array
                    Target values
        y_pred    : array
                    Predicted values
        normalize : bool - False
                    Se normalize for False os valores da matriz de confusão são reais,
                    caso contrário a matriz de confusão apresenta o percentual.
    
    	Returns
    	-------
    	dict : valores de cada métrica
    	"""
        resultados = {'accuracy': accuracy_score(y_true, y_pred),
                      'f1 score': f1_score(y_true, y_pred, average='weighted'),
                      'precision': precision_score(y_true, y_pred, average='weighted'),
                      'recall': recall_score(y_true, y_pred, average='weighted'),
                     }
        return resultados
    
    @classmethod
    def __binary_classification(cls, y_true, y_pred, y_probs, normalize=False):
        """
    	Calculates some metrics for binary classification problems
    
    	Parameters
    	----------            
        y_true    : array
                    Target values
        y_pred    : array
                    Predicted values
        normalize : bool - False
                    If normalize to False the values of the confusion matrix are real,
                    otherwise, the confusion matrix shows the percentage..
    
    	Returns
    	-------
    	dict : values for each metric
    	"""
        results =    {'accuracy': accuracy_score(y_true, y_pred),
                      'f1_score': f1_score(y_true, y_pred),
                      'precision': precision_score(y_true, y_pred),
                      'recall': recall_score(y_true, y_pred),
                      'roc_auc': roc_auc_score(y_true, y_probs)
                     }        
        return results
    
    @classmethod
    def classification(cls, y_true, y_pred, y_probs, normalize=False):
        """
    	Checks which classification method will be applied: binary or multiclass
    
    	Parameters
    	----------            
        y_true    : array
                    Target values
        y_pred    : array
                    Predicted values
        normalize : bool - False
                    If normalize to False the values of the confusion matrix are real,
                    otherwise, the confusion matrix shows the percentage.
    
    	Returns
    	-------
    	dict: values for each metric
    	"""
        if len(set(y_true)) > 2:
            res = cls.__multiclass_classification(y_true, y_pred)
        else:
            res = cls.__binary_classification(y_true, y_pred, y_probs)
        return res
            
        
    @classmethod
    def clusterization(cls, X, labels):
        """
    	Calculates some metrics on clustering quality
    
    	Parameters
    	----------            
        X      : array[array], shape (n_linha, n_colunas)
                 Matrix with the values that were used in the cluster
        labels : array, shape (n_linha, 1)
                 Vector with labels selected by the clustering method (eg KMeans)
    
    	Returns
    	-------
    	dict : values for each metric
    	"""
        return {'silhouette': silhouette_score(X, labels, metric='euclidean'),
                'calinski_harabaz': calinski_harabaz_score(X, labels)
                }
